{"path":"Files/Ling 430 - Handout 15 - Intro to Neural Networks.pdf","text":"Ling 430 March 25th – 28th, 2022 Intro to Neural Networks 1. Neural Networks • (Artificial) Neural networks are complex machine learning algorithms consisting of a collection of interconnected units (neurons) that work together to solve a particular problem • ANNs are inspired by biological neural networks: Within a biological neuron, a signal passes through dendrites into the nucleus, then leaves the neuron through an axon--- and that signal is then passed to another neuron. Signals passing through certain dendrites effectively amplify those signals. • Below is a standard representation of a fully connected artificial neural network. Each neuron (the circles) in one layer is connected to each neuron in the next layer. The input layer consists of our predictor features (i.e., independent variables), ending in certain outputs (i.e., predictions or dependent variables). If containing 3+ layers, we call this a deep neural network. 2. Starting simple: The Perceptron • The perceptron is an ancestor to the modern neural network, but is a simple place to begin to understand how a system of connected neurons work • Basic architecture: 1) A number of features with associated values: X = [x1, x2….xn] The features are the input. We want some way to use these values to calculate an output. Features could be something like word counts of Tfidf values, whereas the output is 0 or 1, negative or positive sentiment. 2) A set of weights that correspond to the features: W = [w1, w2… wn] There will be the same number of features and weights. We want to be able to multiply the features by their corresponding weights in order to get the correct output value (e.g., 0 or 1). Determining the optimal weights to transform from the input to output values is the primary goal of the neuron. 3) An activation function ultimately transforms the calculated value(s) into a decision for whether the neuron fires or not (0 or 1). A function converting an output to 0 or 1 is called a (binary) step function. 4) Then we have the output values, which for now will be 0 or 1 for a binary classification problem. • In terms of our sentiment analysis problem, let’s think of it this way: Perhaps our neuron has determined the following weights for quantifying positive or negative sentiment: weights = {‘good’: 1.2, ‘bad’ : -1.4, ‘amazing’ : 3.2, ‘terrible’ : -4.1} activation: threshold is 0, so positive numbers → 1, negative numbers → 0 A particular document has the following counts: word_counts = {‘good’ : 3, ‘bad’ : 1, ‘amazing’ : 1, ‘terrible’ : 0} So our weighted sum for this document is: (1.2 * 3) + (-1.4 * 1) + (3.2 * 1) + (-4.1 * 0) = 5.4 → 1 (positive) 3. Coding a simple neuron in python • Let’s look at the code for a simple machine learning problem from NLPIA • This is known as a logical OR problem --- as long as at least one of the elements is a 1, return 1 sample_data = [[0,0], [0, 1], [1, 0], [1,1]] expected_results = [0, 1, 1, 1] activation_threshold = 0.5 • The algorithm will need to find weights that convert the paired values into the expected answers. It will check the answers and make changes to the weights as needed. • Produce some random weights. (2) is the number of weights to produce, and these will be between 0 and 1. We divide these by 1000 so they range from 0 to 0.001 import numpy as np weights = np.random.random(2)/1000 • The bias weight is essentially another input feature that is always “on”--- this guards against problems when the inputs are all 0 but the output is not 0 bias_weight = np.random.random() / 1000 • Before we start to make corrections to our weights, let’s set up how this code works to calculate the output value for each data point. Notice we multiply each of the two input values by the two corresponding weights, and add the bias input: for idx, sample in enumerate(sample_data): input_vector = np.array(sample) activation_level = np.dot(input_vector, weights) + (bias_weight * 1) print (activation_level) if activation_level > activation_threshold: output = 1 else: output = 0 print (output) • Now let’s think about how our code can update the weights to get more correct answers. We will: 1) Loop though the data n times (say, 5, if that does the job) 2) Each time, we calculate the outputs for each input 3) Then, we compare to the expected answers and see how many were correct 4) We then adjust the weights for each value in the input and the bias; this is a simple method below that checks the difference from the correct answer (0 if already correct, 1 or -1 if not) and multiplies it by the value of the input, then adds that to the weight for iteration_num in range(5): correct_answers = 0 for idx, sample in enumerate(sample_data): input_vector = np.array(sample) activation_level = np.dot(input_vector, weights) + (bias_weight * 1) if activation_level > activation_threshold: output = 1 else: output = 0 if output == expected_results[idx]: correct_answers += 1 new_weights = [] #time to assign new weights for i, value in enumerate(sample): new_weights.append((expected_results[idx] - output) * value + weights[i]) bias_weight = (expected_results[idx] - output) * 1 + bias_weight weights = np.array(new_weights) print (correct_answers) 4. On to neural networks: Problems with the perceptron Consider the potential input data below and its associated expected outputs. What is the correlation between the two features with the output? Why would this be a problem with our simple model? inputs for two features expected output [0, 0] 0 [0, 1] 1 [1, 0] 1 [1, 1] 0 • This data demonstrates a logical XOR operation. How is this different from OR? • Data such as this is not linearly separable, and was a roadblock in the development of AI (leading to an “AI winter”). Any ideas on how to have our computers learn patterns like these? • Think back to our sentiment analysis problem. What might be a problem we encountered in the labeling that might mirror the XOR patter above? 5. Deep Neural Networks and Hidden Layers • Currently our perceptron model looks something like: • Note that the inputs in no way interact with each other; they are essentially independent like in our Naïve Bayes model • To accommodate this need, we can add a hidden layer of neurons between the input and output layers • Each input layer has weights to each neuron in the hidden layer, so the model can now take into account interactions between the input variables: • We can even have multiple hidden layers: • And what do these hidden neurons represent, exactly? Let’s think about this in terms of image recognition: - The input layer might be the value of every pixel, and the output layer is “cat” or “not cat”. - The first hidden layer might be collections of pixels that go together to indicate lines and edges - The second here might be lines and edges that form things like ears, whiskers, or a tail - The third might be combinations of smaller body parts that exemplify certain larger parts, like a feloid head or leg - And those in turn are weighted to determine whether the image is of a cat or not • In reality, it can be difficult to determine what a particular neuron represents in human terms, even when the algorithm works • Back to sentiment analysis--- what could the hidden layers represent? • How many hidden layers, and neurons in these layers, do we need? While there are some general guidelines and advanced methods for optimizing this, we often just experiment to see what results in the highest accuracy when applied to a new dataset 5. Activation Functions • We’ve only mentioned one activation function, the step function: convert number over some threshold to 1, numbers below this threshold to 0 • However, in order to model non-linear relations we need a non-linear activation function. Here are few commonly used: 1) relu (rectified linear units): Easiest to understand--- positive values remain as they are, negative values are converted to 0 2) sigmoid: Values are converted to a range from 0 to 1 following a sigmoid curve 3) tanh: Values covered to 0 to 1 range following a hyperbolic tangent 6. Backpropagation • So how does the algorithm figure out all these weights? • First let’s look at the code for setting up our layers and their associated weights: import numpy as np • This will be a neural net with three layers: 3 input neurons, 4 hidden neurons, and 1 output neuron import numpy as np np.random.seed(1) #keep the same values generating def relu(x): return (x>0) * x def relu2deriv(x): return (x > 0) streetlights = np.array([[1, 0, 1], [0, 1, 1], [0, 0, 1], [1, 1, 1]]) walk_or_stop = np.array([[1, 1, 0, 0]]).T alpha = 0.2 #amount to scale weight changes by hidden_size = 4 #4 neurons in hidden layer. weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1 #12 weights, from 3 input neurons to 4 hidden neurons weights_1_2 = 2 * np.random.random((hidden_size, 1)) -1 • Now we train the model, adjusting weights during 60 iterations. In each iteration we want to minimize the cost or loss function --- the difference between the calculated outputs and the expected outputs. for iteration in range(60): #60 iterations for predicting and backpropagating to adjust weights layer_2_error = 0 layer_1 = relu(np.dot(layer_0, weights_0_1)) layer_2 = np.dot(layer_1, weights_1_2) layer_2_error += np.sum((layer_2 - walk_or_stop[i:i+1]) ** 2) • To minimize this loss, we will need to make adjustments in the weights. Determining the correct amount to update each weight is known as backpropagation. • To do this, we first we find delta for the output--- how far was the calculated answer from the actual answer? 1) First, update the weights from the hidden layer to the output by multiplying the values of the hidden layer by the delta and subtract that amount from the old weights; that is, nodes with higher values will have contributed more to the error, so we want to make larger corrections to their weights. layer_2_delta = (layer_2 - walk_or_stop[i:i+1]) weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta) 2) Then, proceed to update the weights from the input layer to the hidden layer. We calculate delta by multiplying the delta values calculated in step (1) by the weights. Basically, we’re passing along the delta to weights in previously layers, apportioning it to the neurons with the highest values. You will also need to multiply these values by the slope of these values in the activation function--- if a neuron has a value of 0, we don’t need to update its weight; That’s what the function “relu2deriv” does. layer_1_delta = (layer_2_delta.dot(weights_1_2.T)) * relu2deriv(layer_1) weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta) 7. Keras • Fortunately, we don’t normally code neural networks by hand. We’ll be using the keras package for training neural networks • Let’s train our sentiment analysis program using with a neural network using Kera • We want the algorithm to calculate output values given input values. The inputs will be our count vectors, the outputs are the corresponding sentiment values. • Read in the data, vectorize and split into training and testing sets just like you would with other machine learning algorithms • Keras code for a three-layer neural network - Sequential is the model type, in this case a stack of ordered layers • Dense is a fully connected layer from keras.models import Sequential from keras.layers import Dense • We want three layers: (1) The input layer, which will be the size of our input features (2) A hidden layer, having the number of neurons we choose (3) The output layer, with a single neuron since we are making only one prediction (good/bad sentiment) model = Sequential() num_neurons = 300 #this is the number of hidden layers model.add(Dense(num_neurons, input_dim = num_features, activation = 'relu')) #this is our hidden layer. But being the first layer we add, we tell it how many inputs are coming in. Using ‘relu’ activation; you might also consider ‘tanh’ or ‘sigmoid’ model.add(Dense(1, activation = 'sigmoid')) #our output layer. ‘sigmoid’ activation is best for binary classification • Compiling and fitting the model: model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) model.fit(x_train, y_train, epochs = 10, batch_size=50) #loss--- ‘binary crossentropy’ calculates the loss with respect to two classes (like 0 and 1). It’s logarithmic, so small differences yield small errors, while big differences yield exaggerated errors #optimizer--- before we used gradient descent where we had a set ‘alpha’ for scaling our weight updates. ‘adam’ is more sophisticated and can adapt the value of alpha. #metrics--- shows how our accurate our algorithm is on the training data for each epoch #epochs--- the total number of training iterations. You can play around with this value. At some point, more epochs will result in no improvement, or even overfitting #batch_size--- the number of inputs to assess before updating weights. Another hyperparameter you can play with print (model.evaluate(x_test, y_test)) • How well does this do compared to Naïve Bayes?","libVersion":"0.3.1","langs":""}