{"path":"Files/Ling 430 - Handout #9 - Sentiment Analysis.pdf","text":"Ling 430 February 16th – 18th, 2022 Machine Learning: Sentiment Analysis 1. Sentiment Analysis • Now that we’ve converted our documents into term frequency and TF-IDF vectors, we can also analyze and categorize their semantic context • Sentiment analysis is trying to determine the sentiment of a particular document--- the simplest form is determining “positive” vs. “negative” sentiment • The goal is to input text and output a number 0 (negative) or 1 (positive). text > TD-IDF vectors > calculations > 0 (negative) or 1 (positive) How might you go about quantifying sentiment? 2. Machine Learning • Traditional programming: we tell the computer how to detect a pattern • Machine learning: we give the computer data, and it learns to detect a pattern Supervised machine learning: Data is labeled with categories. Computer learns to imitate the human labelling. Unsupervised machine learning: Data is given without labels; Computer tries to find ways to sort the data meaningfully • We’ll be starting with classification tasks--- predicting a label from a set of labels, e.g., “positive” or “negative” (in this case, binary classification) 3. Toy Machine Learning Problem Task: Train computer to classify a vowel as [æ] or [ɛ] based on its F1 value. Feed the computer the following data (0 = [æ], 1 = [ɛ]) F1 Vowel (label) 810 0 773 0 794 0 688 1 755 1 726 1 This is our training set--- the data the program uses to learn from. We then may have a similar testing set, where the algorithm uses the F1 to predict the vowel, and then checks the labels to see how well it did 4. Machine Learning with Naïve Bayes • Naïve Bayes Classification is a simple algorithm for classifying data • We have a number of predictive features (or independent variables) that may affect the classification • Example task: can we train the computer to determine if first names seem more masculine or feminine based on their spelling? • What features might we want to include? Perhaps: first letter, last letter, length of name, clusters of letters, etc. • How Naïve Bayes works: We feed the algorithm a name, say “Victoria”. Let’s say we just use two features--- first letter and last letter. We multiply the conditional frequencies of each variable--- what percent of the time does feature X result in label Y--- by the class frequency--- how likely are the different label to occur naturally? We do that for each possible label and predict the label with the highest probability. That is: 1) likelihood “Victoria” is a male name = percent of male names starting with <v> * percent of male names ending with <a> * likelihood that a random name will be a male name (probably 0.5) 2) likelihood “Victoria” is a female name = percent of female names starting with <v> * percent of female names ending in <a> * likelihood that a random name will be a female name (probably 0.5) If (1) is higher, the label “male” is assigned. If (2) is higher, “female” is assigned. • Naïve Bayes assumes there are no interactions between features/variables (e.g., that final ‘a’ is more likely female normally, but more likely male if the first letter is, say, <t>) 5. Naïve Bayes Example i) Read in the data • For this problem nltk has a document containing male names and a document containing female names. Let’s read this into a list in the form of tuples--- name + gender label--- and then shuffle it: from nltk.corpus import names import random male_names = [(name, ‘male’) for name in names.words(‘male.txt’)] female_names = [(name, ‘female’) for name in names.words(‘female.txt’)] names = male_names + female_names random.shuffle(names) ii) Extract the features • We’ll be feeding our algorithm a dataframe of features with their values and a list of labels • Let’s split the names and the labels first, now that they’re been sorted training_names = [name[0] for name in names] labels = [name[1] for name in names] • We have two features to train on: first_letter and last_letter of the name • Naïve Bayes models usually train on numerical data, so we will need to convert our letters to numbers using the following encoder: feature_letters = \" abcdefghijklmnopqrstuvwxyz\" encoder = {letter : i for i, letter in enumerate(feature_letters)} • Now we’ll create a list of dictionaries for each name. In each dictionary will be the numerical values of the first and last letter of each name. list_of_dicts = [] for name in training_names: temp_dict = {} temp_dict[‘first_letter’] = encoder[name[0]] temp_dict[‘last_letter’] = encoder[name[-1]] list_of_dicts.append(temp_dict) • Now we convert the list of dictionaries to a pandas dataframe, indexing each row with the names import pandas as pd df = pd.DataFrame(list_of_dicts, index = training_names) iii) Making training and testing sets • We can split our data into training and testing sets to assess how well our model works on data it didn’t train on. An 80-20 split is common: split_point = int(0.8*len(labels)) x_train = df.iloc[:split_point] y_train = labels[:split_point] x_test = df.iloc[split_point:] y_test = labels[split_point:] iv) Feed data into Naïve Bayes model • There are several types of Naïve Bayes classifiers. We’ll use the categorical one for this problem, since our values--- numbers representing letters--- are essentially unordered, corresponding to qualitative rather than quantitative data (i.e, ‘a,’ now 1, is not really less than ‘b,’ now 2). from sklearn.naive_bayes import CategoricalNB nb = CategoricalNB() nb = nb.fit(x_train, y_train) v) Analyze model accuracy • How well did our model predict the genders of the names in the testing set? print (nb.score(x_test, y_test)) vi) Predict with our model • We can submit new names (real or made up) to see how the model classifies it • Note we must first convert the name to a dataframe with the same features extracted as we did for the training: new_name = ‘pala’ data = {'first_letter' : encoder[new_name[0].lower()], ‘last_letter’ : \\ encoder[new_name[-1].lower()]} new_df = pd.DataFrame(data, index=[new_name]) print (nb.predict(new_df)) vii) Analyzing the feature probabilities • Below is some code that gives the n most informative features for the “male” and “female” classes: probs = {} for i, feature in enumerate(nb.feature_names_in_): probs[feature] = np.array(nb.feature_log_prob_[i][0]) - \\ np.array(nb.feature_log_prob_[i][1]) inf_features = pd.DataFrame(probs, index = [letter for letter in feature_letters]) num_features = 10 for feature in nb.feature_names_in_: class_1 = str(inf_features[feature].nlargest(num_features)) class_2 = str(inf_features[feature].nsmallest(num_features)) print (\"Most informative \" + nb.classes_[0] + \" \" + feature + '\\n' + class_1) print (\"Most informative \" + nb.classes_[1] + \" \" + feature + '\\n' + class_2) 6. Sentiment analysis • What could be the features we input to our Naïve Bayes model for sentiment analysis? i) Binary bag of words ii) Count or Term Frequency BoW vectors iii) TF-IDF BoW vectors (or n-gram vectors instead of word vectors) 7. BoW models • Binary BoW vectors just give 0s and 1s for whether a word occurs in a document--- it doesn’t matter how often it occurs: ‘Sally saw the cat and the cat saw Sally. Now Sally owns a cat.” → Sally saw the cat and now owns a pizza porcupine, etc. 1 1 1 1 1 1 1 1 0 0 • Count BoW vectors would give the full count of each word in each document: Sally saw the cat and now owns a pizza porcupine, etc. 3 2 2 3 1 1 1 1 0 0 • Term Frequency BoW vectors would divide these values by the length of the document: Sally saw the cat and now owns a pizza porcupine, etc. 0.21 0.14 0.14 0.21 0.07 0.07 0.07 0.07 0 0 • And TF-IDF BoW vectors would give term frequencies divided by the inverse document frequency 8. Sentiment Analysis with Word Count BoWs • Let’s modify our script for gender prediction to predict sentiment (‘positive’ or ‘negative’) based on the counts of words in each document 1) Read in the movie reviews from nltk.corpus. The reviews have two categories, “pos” and “neg”: from nltk.corpus import movie_reviews import random pos_documents = [(' '.join(list(movie_reviews.words(doc))), \"pos\") for doc in \\ movie_reviews.fileids(\"pos\")] neg_documents = [(' '.join(list(movie_reviews.words(doc))), \"neg\") for doc in \\ movie_reviews.fileids(\"neg\")] 2) As in the gender prediction script, concatenate the two sets of documents, shuffle them, and then separate the text from the labels into lists (a list of lists for the texts, since they are already tokenized) 3) Produce a dataframe of word counts for each document (the rows) with columns for each word in the corpus vocab. Fortunately, there’s a quicker way to do this than we saw before, using CountVectorizer (use TfidfVectorizer for Tfidf vectors): import pandas as pd from sklearn.feature_extraction.text import CountVectorizer word_vecs = CountVectorizer() X = word_vecs.fit_transform(documents) df = pd.DataFrame(X.todense(), columns=word_vecs.get_feature_names_out()) 4) Split the data set into 80% for training, 20% for testing 5) Create a Naïve Bayes classifier and train it on the training dataset. This time, use the MultinomialNB instead of CategoricalNB; Our data is numerical and continuous: from sklearn.naive_bayes import MultinomialNB nb = MultinomialNB() nb = nb.fit(x_train, y_train) 6) Find the accuracy on the testing dataset: print (nb.score(x_test, y_test)) 7) Feed the model a new document to predict. Since you have already created the CountVectorizer model, you’ll just want to transform your document in accordance with the model, rather than fit and transform (that is, you want all the same column names for your new document as the training set) new_review = [“your review”] X = word_vecs.transform(new_review) new_df = pd.DataFrame(X.todense(), columns=word_vecs.get_feature_names_out()) print (nb.predict(new_df)) 8) Inspect the ranked list of words based on their likelihood to predict a positive or negative outcome. What does this tell us about the strengths and weaknesses of this approach? How might we improve our model? import numpy as np probs = np.array(np.array(nb.feature_log_prob_[1] - nb.feature_log_prob_[0])) inf_features = pd.DataFrame(probs, index = word_vecs.get_feature_names_out(), \\ columns = ['prob']) inf_features = inf_features.sort_values(by = 'prob')","libVersion":"0.5.0","langs":""}